# Dexterous Manipulation



## Talks

- 香港大学在读博士罗谦：模仿学习中的数据采集系统, [[bilibili](https://www.bilibili.com/video/BV1VGwneVEzj/?spm_id_from=333.337.search-card.all.click&vd_source=02d17afa86e1a24aea6ec3147fc08936)] [[Qian Luo](https://qianqianlo.github.io/)]

## Grasping

- **DexGraspNet**: A Large-Scale Robotic Dexterous Grasp Dataset for General Objects Based on Simulation, *ICRA 2023*. [[Paper](https://arxiv.org/abs/2210.02697)] [[Website](https://pku-epic.github.io/DexGraspNet/)] [[Code](https://github.com/PKU-EPIC/DexGraspNet)]
- **DGTR**: Dexterous Grasp Transformer, *CVPR 2024*. [[Paper](https://arxiv.org/abs/2404.18135)] [[Website](https://isee-laboratory.github.io/dgtr/)] [[Code](https://github.com/iSEE-Laboratory/DGTR)]

- **GenDexGrasp**: Generalizable Dexterous Grasping, *ICRA 2023*. [[Paper](https://arxiv.org/abs/2210.00722)] [[Website](https://sites.google.com/view/gendexgrasp/home)] [[Code](https://github.com/tengyu-liu/GenDexGrasp)]
- **UniDexGrasp**: Universal Robotic Dexterous Grasping via Learning Diverse Proposal Generation and Goal-Conditioned Policy, *CVPR 2023*. [[Paper](https://arxiv.org/abs/2303.00938)] [[Website](https://pku-epic.github.io/UniDexGrasp/)] [[Code](https://github.com/PKU-EPIC/UniDexGrasp)] [[PKU-EPIC](https://github.com/PKU-EPIC)]
- **UniDexGrasp++**: Improving Dexterous Grasping Policy Learning via Geometry-aware Curriculum and Iterative Generalist-Specialist Learning, *ICCV 2023 Best Paper Finalist*. [[Paper](https://arxiv.org/abs/2304.00464)] [[Website](https://pku-epic.github.io/UniDexGrasp++/)] [[Code](https://github.com/PKU-EPIC/UniDexGrasp2)] [[PKU-EPIC](https://github.com/PKU-EPIC)]
- **UniGraspTransformer**: Simplified Policy Distillation for Scalable Dexterous Robotic Grasping, *arXiv 2024*. [[Paper](https://arxiv.org/abs/2412.02699)] [[Website](https://dexhand.github.io/UniGraspTransformer/)] [[Code](https://github.com/microsoft/UniGraspTransformer)] [[microsoft](https://github.com/microsoft)]
- **GraspXL**: Generating Grasping Motions for Diverse Objects at Scale, *ECCV 2024*. [[Paper](https://arxiv.org/abs/2403.19649)] [[Website](https://eth-ait.github.io/graspxl/)] [[Code](https://github.com/zdchan/graspxl)]
- **SpringGrasp**: Synthesizing Compliant, Dexterous Grasps under Shape Uncertainty, *arXiv 2024*. [[Paper](https://arxiv.org/abs/2404.13532)] [[Code](https://github.com/Stanford-TML/SpringGrasp_release)] [[Website](https://stanford-tml.github.io/SpringGrasp/)] [[Stanford-TML](https://github.com/Stanford-TML)]
- **Catch It!** Learning to Catch in Flight with Mobile Dexterous Hands, *arXiv 2024*. [[Paper](https://arxiv.org/abs/2409.10319)] [[Website](https://mobile-dex-catch.github.io/)] [[Code](https://github.com/hang0610/Catch_It)]
- **Grasp as You Say**: Language-guided Dexterous Grasp Generation, *NeurIPS 2024*. [[Paper](https://arxiv.org/abs/2405.19291)] [[Website](https://isee-laboratory.github.io/DexGYS/)] [[Code](https://github.com/iSEE-Laboratory/Grasp-as-You-Say)] [[iSEE-Laboratory, Sun Yat-sen University](https://github.com/iSEE-Laboratory)]
- **DexGraspNet 2.0**: Learning Generative Dexterous Grasping in Large-scale Synthetic Cluttered Scenes, *CoRL 2024*. [[Paper](https://arxiv.org/abs/2410.23004)] [[Website](https://pku-epic.github.io/DexGraspNet2.0/)] [[Code](https://github.com/PKU-EPIC/DexGraspNet2)] [[PKU-EPIC](https://github.com/PKU-EPIC)]

---

## Manipulation

- **Hand-DAPG**: Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations, *RSS 2018*. [[Paper](https://arxiv.org/abs/1709.10087)] [[Website](https://sites.google.com/view/deeprl-dexterous-manipulation)] [[Code](https://github.com/aravindr93/hand_dapg)]

- **RoboPianist**: Dexterous Piano Playing with Deep Reinforcement Learning, *CoRL 2023*. [[Paper](https://arxiv.org/abs/2304.04150)] [[Code](https://github.com/google-research/robopianist)] [[Docs](https://google-research.github.io/robopianist/)]
- ynchronize Dual Hands for Physics-Based Dexterous Guitar Playing, *SIGGRAPH Asia 2024*. [[Paper](https://arxiv.org/abs/2409.16629)] [[Website](https://pei-xu.github.io/guitar)] [[Code](https://github.com/xupei0610/guitar)]
- **Sequential Dexterity**: Chaining Dexterous Policies for Long-Horizon Manipulation, *CoRL 2023*. [[Paper](https://arxiv.org/abs/2309.00987)] [[Website](https://sequential-dexterity.github.io/)] [[Code](https://github.com/sequential-dexterity/SeqDex)]
- **DexMV**: Imitation Learning for Dexterous Manipulation from Human Videos, *ECCV 2022*. [[Paper](https://arxiv.org/abs/2108.05877)] [[Website](https://yzqin.github.io/dexmv/)] [[Code](https://github.com/yzqin/dexmv-sim)]

- Complementarity-Free Multi-Contact Modeling and Optimization for Dexterous Manipulation, *arXiv 2024*. [[Paper](https://arxiv.org/abs/2408.07855)] [[Code](https://github.com/asu-iris/Complementarity-Free-Dexterous-Manipulation)]

- **DexArt**: Benchmarking Generalizable Dexterous Manipulation with Articulated Objects, *CVPR 2023*. [[Paper](https://arxiv.org/abs/2305.05706)] [[Website](https://www.chenbao.tech/dexart/)] [[Code](https://github.com/Kami-code/dexart-release)]

- **TCDM**: Learning Dexterous Manipulation from Exemplar Object Trajectories and Pre-Grasps, *ICRA 2023*. [[Paper](https://arxiv.org/abs/2209.11221)] [[Website](https://pregrasps.github.io/)] [[Code](https://github.com/facebookresearch/TCDM)]

- Generalization in Dexterous Manipulation via Geometry-Aware Multi-Task Learning, *arXiv 2021*. [[Paper](https://arxiv.org/abs/2111.03062)] [[Website](https://wenlong.page/geometry-dex/)] [[Code](https://github.com/huangwl18/geometry-dex)]

- **DexPoint**: Generalizable Point Cloud Reinforcement Learning for Sim-to-Real Dexterous Manipulation, *CoRL 2022*. [[Paper](https://arxiv.org/abs/2211.09423)] [[Website](https://yzqin.github.io/dexpoint/)] [[Code](https://github.com/yzqin/dexpoint-release)]

- **DexDeform**: Dexterous Deformable Object Manipulation with Human Demonstrations and Differentiable Physics, *ICLR 2023*. [[Paper](https://openreview.net/pdf?id=LIV7-_7pYPl)] [[Code](https://github.com/sizhe-li/DexDeform)]

- **Dex-Affordance**: Learning Generalizable Dexterous Manipulation from Human Grasp Affordance, *CoRL 2022*. [[Paper](https://arxiv.org/abs/2204.02320)] [[Website](https://kristery.github.io/ILAD/)] [[Code](https://github.com/kristery/dex-affordance)]

- **H-InDex**: Visual Reinforcement Learning with Hand-Informed Representations for Dexterous Manipulation, *NeurIPS 2023*. [[Paper](https://arxiv.org/abs/2310.01404)] [[Website](https://yanjieze.com/H-InDex/)] [[Code](https://github.com/YanjieZe/H-InDex)]



## Data Collection

### Vision Teleporation

- **DexPilot**: Vision Based Teleoperation of Dexterous Robotic Hand-Arm System, *ICRA 2020*. [[Paper](https://arxiv.org/abs/1910.03135)] [[Website](https://sites.google.com/view/dex-pilot)]
- **From One Hand to Multiple Hands**: Imitation Learning for Dexterous Manipulation from Single-Camera Teleoperation, *IROS 2022*. [[Paper](https://arxiv.org/abs/2204.12490)] [[Website](https://yzqin.github.io/dex-teleop-imitation/)] [[Code](https://github.com/yzqin/dex-hand-teleop)]
- **Dexterous Imitation Made Easy**: A Learning-Based Framework for Efficient Dexterous Manipulation, *arXiv 2022*. [[Paper](https://arxiv.org/abs/2203.13251)] [[Website](https://nyu-robot-learning.github.io/dime/)] [[Code](https://github.com/NYU-robot-learning/DIME-Models)] [[NYU-robot-learning](https://github.com/NYU-robot-learning)]
- :fire: **AnyTeleop**: A General Vision-Based Dexterous Robot Arm-Hand Teleoperation System, *RSS 2023*. [[Paper](https://arxiv.org/abs/2307.04577)] [[Website](https://yzqin.github.io/anyteleop/)] [[Code](https://github.com/dexsuite/dex-retargeting)] [UCSD]

### VR-Controlled Teleporation

- **HATO**: Learning Visuotactile Skills with Two Multifingered Hands, *arXiv 2024*. [[Paper](https://arxiv.org/abs/2404.16823)] [[Website](https://toruowo.github.io/hato/)] [Code](https://github.com/toruowo/hato) [UC Berkeley]

- **Bunny-VisionPro**: Real-Time Bimanual Dexterous Teleoperation for Imitation Learning, *arXiv 2024*. [[Paper](https://arxiv.org/abs/2407.03162)] [[Website](https://dingry.github.io/projects/bunny_visionpro.html)] [[Code](https://github.com/Dingry/BunnyVisionPro)]
- **H2O**: Learning Human-to-Humanoid Real-Time Whole-Body Teleoperation, *IROS 2024*. [[Paper](https://arxiv.org/abs/2403.04436)] [[Website](https://human2humanoid.com/)] [[Code](https://github.com/LeCAR-Lab/human2humanoid)] [[LeCAR-Lab, CMU](https://github.com/LeCAR-Lab)]
- **OmniH2O**: Universal and Dexterous Human-to-Humanoid Whole-Body Teleoperation and Learning, *CoRL 2024*. [[Paper](https://arxiv.org/abs/2406.08858)] [[Website](https://omni.human2humanoid.com/)] [[Code](https://github.com/LeCAR-Lab/human2humanoid)] [[LeCAR-Lab, CMU](https://github.com/LeCAR-Lab)]

### Motion Capture System

- :fire: **DexCap**: Scalable and Portable Mocap Data Collection System for Dexterous Manipulation, *RSS 2024*. [[Paper](https://arxiv.org/abs/2403.07788)] [[Website](https://dex-cap.github.io/)] [[Code](https://github.com/j96w/DexCap)]
- :fire: **ACE**: A Cross-Platform Visual-Exoskeletons System for Low-Cost Dexterous Teleoperation, *CoRL 2024*. [[Paper](https://arxiv.org/abs/2408.11805)] [[Website](https://ace-teleop.github.io/)] [[Code](https://github.com/ACETeleop/ACETeleop)] [[Hardware](https://github.com/ACETeleop/ACE_hardware)]

-----

## Simulation

- **Bi-DexHands**: Bimanual Dexterous Manipulation via Reinforcement Learning, *arXiv 2022*. [[Paper](https://arxiv.org/abs/2206.08686)] [[Code](https://github.com/PKU-MARL/DexterousHands)] [[Docs](https://pku-marl.github.io/DexterousHands/)] [[PKU-MARL](https://github.com/PKU-MARL)]

- **QuasiSim**: Parameterized Quasi-Physical Simulators for Dexterous Manipulations Transfer, *ECCV 2024*. [[Paper](https://arxiv.org/abs/2404.07988)] [[Website](https://meowuu7.github.io/QuasiSim/)] [[Code](https://github.com/Meowuu7/QuasiSim)]
- 